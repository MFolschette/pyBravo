{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Un scénario complet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques informations et paramètres pour commencer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "def is_interactive():\n",
    "    import __main__ as main\n",
    "    return not hasattr(main, '__file__')\n",
    "\n",
    "Param_SBMLfile = \"../data/iLiverCancer1715.xml\"\n",
    "Param_Pourcentage = 1.1\n",
    "Param_RNASeqFilename = \"../data/LiverCancerTCGA_male.csv\"\n",
    "Param_MaxIndegreeInRRG = 18\n",
    "Param_Drug = \"Sorafenib (USAN/INN)\"\n",
    "Param_NumberOfSample = 100\n",
    "debugon = True\n",
    "Param_DoReconstruction = True\n",
    "WithRef=False\n",
    "BIF_file = \"\"\n",
    "must_save_bif = True\n",
    "\n",
    "if not is_interactive():\n",
    "    import sys,getopt\n",
    "\n",
    "    optlist, args = getopt.getopt(sys.argv[1:], 'i:p:r:m:d:s:vRwP:Q:b:', [\"input\", \"percentage\",\"rna\",\"maxdegree\",\"drug\",\"samples\",\"verbose\",\"with-reconstruction\",\"with-ref\",\"probas\",\"probasref\",\"bif\"])\n",
    "\n",
    "    for o,v in optlist:\n",
    "        if  o in (\"-i\",\"--input\"):\n",
    "            Param_SBMLfile = v\n",
    "    \n",
    "        if o in (\"-r\",\"--rna\"):\n",
    "            Param_RNASeqFilename = v\n",
    "    \n",
    "        if o in (\"-p\",\"--percentage\"):\n",
    "            Param_Pourcentage = float(v)\n",
    "    \n",
    "        if o in (\"-m\",\"--maxdegree\"):\n",
    "            Param_MaxIndegreeInRRG = int(v)\n",
    "    \n",
    "        if o in (\"-d\",\"--drug\"):\n",
    "            Param_Drug = v\n",
    "        \n",
    "        if o in (\"-s\",\"--samples\"):\n",
    "            Param_NumberOfSample = int(v)\n",
    "    \n",
    "        if o in (\"-v\",\"--verbose\"):\n",
    "            debugon = True\n",
    "            \n",
    "        if o in (\"-R\",\"--with-reconstruction\"):\n",
    "            Param_DoReconstruction = True\n",
    "\n",
    "        if o in (\"-w\",\"--with-ref\"):\n",
    "            WithRef = True\n",
    "\n",
    "        if  o in (\"-P\",\"--probas\"):\n",
    "            Param_ProbaReactionsFilename = v\n",
    "            \n",
    "        if  o in (\"-Q\",\"--probasref\"):\n",
    "            Param_ProbaReactionsREFFilename = v\n",
    "\n",
    "        if o in (\"-b\",\"--bif\"):\n",
    "            BIF_file = v\n",
    "\n",
    "# internal variables\n",
    "#import shutils\n",
    "#shutils.copy(Param_SBMLfile,\"../tmp\")\n",
    "import os\n",
    "\n",
    "Param_SBMLfileBN = \"../tmp/\"+os.path.basename(Param_SBMLfile)\n",
    "if BIF_file==\"\":\n",
    "    BIF_file = Param_SBMLfileBN.replace(\".xml\",\".bif\")\n",
    "\n",
    "\n",
    "\n",
    "PC_Endpoint = \"http://rdf.pathwaycommons.org/sparql\"\n",
    "RXN_EC_file = Param_SBMLfileBN.replace(\".xml\",\".rxn\")\n",
    "BIF_file = Param_SBMLfileBN.replace(\".xml\",\".bif\")\n",
    "Param_RRGFilename = Param_SBMLfileBN.replace(\".xml\",\".rrg\")\n",
    "Param_ProbaReactionsFilename = Param_SBMLfileBN.replace(\".xml\",\".prob\")\n",
    "#whichsolver = \"gurobi\"\n",
    "whichsolver = \"cglpk\"\n",
    "\n",
    "\n",
    "filenameCorrespondanceEnsemblGenenames = \"../tables/Correspondance_Ensembl_genename.txt\"\n",
    "filenameCorrespondanceEnsemblEnzymes = \"../tables/Correspondance_Enzymes_genenames.txt\"\n",
    "filenameCorrespondanceEnsemblTransporters = \"../tables/Correspondance_Transporters_genenames.txt\"\n",
    "filenameKEGGDrugsGenes = \"../tables/Public_KEGGDRUG_Targets.csv\"\n",
    "filenameCorrespondanceEnsemblMeanLength = \"../tables/Correspondance_Ensembl_MeanTranscriptSize.txt\"\n",
    "Param_ProbaReactionsREFFilename = Param_SBMLfileBN.replace(\".xml\",\".prob_ref\")\n",
    "\n",
    "\n",
    "# internal function can be edited\n",
    "def Binarized(x,m,s,gene=\"null\"):\n",
    "    x=log(0.0001+x)\n",
    "    InfBoundCoeff=0 #0.46 #0.46\n",
    "    SupBoundCoeff=10000000 # 0.46\n",
    "    if (x<m-InfBoundCoeff*s):\n",
    "        return 0\n",
    "    if (x>m+SupBoundCoeff*s):\n",
    "        return 1\n",
    "    return 1\n",
    "\n",
    "\n",
    "def Binarized1(x,m,s,gene=\"null\"):\n",
    "    InfBoundCoeff=0.1\n",
    "    m=AllGeneMeans.get(gene)\n",
    "    if (m):\n",
    "        if (m !=0):\n",
    "            if (x/m<InfBoundCoeff):\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "    return 0\n",
    "\n",
    "def Binarized3(x,m,s,gene=\"null\"):\n",
    "    InfBoundCoeff=1\n",
    "#    m=AllGeneMeans.get(gene)\n",
    "    m=1\n",
    "    if (m):\n",
    "        if (m !=0):\n",
    "            if (x/m<InfBoundCoeff):\n",
    "                return 0\n",
    "            else:\n",
    "                return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import optlang # NB : due to a bug in cobrapy, optlang must be imported before cobra\n",
    "import cobra\n",
    "from cobra.flux_analysis import flux_variability_analysis\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "import csv\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import networkx as nx\n",
    "from math import log\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pgmpy.models import BayesianModel\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator, BayesianEstimator\n",
    "from pgmpy.factors.discrete import State\n",
    "from pgmpy.sampling import BayesianModelSampling\n",
    "from pgmpy.readwrite import BIFReader, BIFWriter\n",
    "\n",
    "\n",
    "#from optlang import Model,Variable,Constraint,Objective\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# a few definition to print on stderr\n",
    "def eprint(*args, **kwargs):\n",
    "    if debugon:\n",
    "        print(*args, file=sys.stderr, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing ../data/iLiverCancer1715.xml for Sorafenib (USAN/INN)\n"
     ]
    }
   ],
   "source": [
    "## DEBUG ONLY\n",
    "begintotal = timer()\n",
    "eprint(\"Testing\",Param_SBMLfile,\"for\",Param_Drug)\n",
    "\n",
    "## END DEBUG ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des listes de correspondances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing all the correspondance tables\n"
     ]
    }
   ],
   "source": [
    "eprint(\"Importing all the correspondance tables\")\n",
    "# Tables 1 et 2: correspondance Ensembl <-> GeneNames (à refaire en SPARQL ?)\n",
    "\n",
    "filename = filenameCorrespondanceEnsemblGenenames\n",
    "\n",
    "EnsemblToGeneNames = dict()\n",
    "GeneNamesToEnsembl = dict()\n",
    "\n",
    "EnsemblToGeneNamesList = dict()\n",
    "GeneNamesToEnsemblList = dict()\n",
    "\n",
    "\n",
    "fd = open(filename,\"r\")\n",
    "\n",
    "lines = fd.readlines()\n",
    "for l in lines:\n",
    "    t=l.split(\";\")\n",
    "    t[2]=t[2].replace(\"\\n\",\"\")\n",
    "    EnsemblToGeneNames[t[0]]=t[2]\n",
    "    GeneNamesToEnsembl[t[2]]=t[0]\n",
    "    if (not EnsemblToGeneNamesList.get(t[0])):\n",
    "        EnsemblToGeneNamesList[t[0]]=list()\n",
    "    if (not GeneNamesToEnsemblList.get(t[2])):\n",
    "        GeneNamesToEnsemblList[t[2]]=list()\n",
    "    EnsemblToGeneNamesList[t[0]].append(t[2])\n",
    "    GeneNamesToEnsemblList[t[2]].append(t[0])\n",
    "    \n",
    "fd.close()\n",
    "\n",
    "# Missing genename associations\n",
    "GeneNamesToEnsembl[\"TGIF\"]=GeneNamesToEnsembl[\"TGIF1\"]\n",
    "GeneNamesToEnsembl[\"CART1\"]=GeneNamesToEnsembl[\"ALX1\"]\n",
    "EnsemblToGeneNames[\"ENSG00000122718\"]=\"OR2S2\"\n",
    "EnsemblToGeneNames[\"ENSG00000155640\"] = \"C10orf12\"\n",
    "GeneNamesToEnsembl[\"C10orf12\"]=\"ENSG00000155640\"\n",
    "EnsemblToGeneNames[\"ENSG00000168260\"] = \"C14orf183\"\n",
    "GeneNamesToEnsembl[\"C14orf183\"]=\"ENSG00000168260\"\n",
    "EnsemblToGeneNames[\"ENSG00000168787\"] = \"OR12D2\"\n",
    "EnsemblToGeneNames[\"ENSG00000170803\"] = \"OR2AG1\"\n",
    "EnsemblToGeneNames[\"ENSG00000171484\"] = \"OR1B1\"\n",
    "EnsemblToGeneNames[\"ENSG00000172381\"] = \"OR6Q1\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tables 3 et 4 : Correspondance (Enzymes,Transporters) <-> Ensembl\n",
    "\n",
    "filename = filenameCorrespondanceEnsemblEnzymes\n",
    "\n",
    "ECTCDBToEnsembl = dict()\n",
    "fd = open(filename,\"r\")\n",
    "\n",
    "lines = fd.readlines()\n",
    "for l in lines:\n",
    "    t=l.split(\";\")\n",
    "    L=t[1].replace(\"\\n\",\"\").split(\",\")\n",
    "    ECTCDBToEnsembl[t[0]]=list()\n",
    "    for g in L:\n",
    "        if (GeneNamesToEnsembl.get(g)):\n",
    "            ECTCDBToEnsembl[t[0]].append(GeneNamesToEnsembl.get(g))\n",
    "fd.close()\n",
    "\n",
    "\n",
    "filename = filenameCorrespondanceEnsemblTransporters\n",
    "\n",
    "fd = open(filename,\"r\")\n",
    "\n",
    "lines = fd.readlines()\n",
    "for l in lines:\n",
    "    t=l.split(\";\")\n",
    "    L=t[1].replace(\"\\n\",\"\").split(\",\")\n",
    "    ECTCDBToEnsembl[t[0]]=list()\n",
    "    for g in L:\n",
    "        if (GeneNamesToEnsembl.get(g)):\n",
    "            ECTCDBToEnsembl[t[0]].append(GeneNamesToEnsembl.get(g))\n",
    "fd.close()\n",
    "\n",
    "# Table 5 : Second filter, the genes present in the RRG must possess a RNASeq value. List of genes having a RNASeq value\n",
    "\n",
    "#Request = \"\"\"curl -o /dev/stdout \"http://bgee.org/?page=gene&gene_id=%%GENEID%%\" -q | grep \"Name\" | awk -F \"<td>|</td>|<th>|</th>\" '{for(i=1;i<NF;i++) {if ($i == \"Ensembl ID\") {printf(\"%s;;\",$(i+2));}; if ($i == \"Name\") {printf(\"%s\\\\n\",$(i+2));};          }    }'>>~/Downloads/missing.csv\"\"\"\n",
    "\n",
    "#fout=open(\"/Users/jeremiebourdon/Downloads/requete.sh\",\"w\")\n",
    "\n",
    "filename = Param_RNASeqFilename\n",
    "fd = open(filename,\"r\")\n",
    "l=fd.readline()\n",
    "RNASeqlistofgenes=list()\n",
    "#missing=\"\"\n",
    "for l in fd:\n",
    "    l=l.replace('\"','').replace('\\n','')\n",
    "    t=l.split(\",\")\n",
    "    geneid=t[0].split(\".\")[0]\n",
    "#    if not (EnsemblToGeneNames.get(geneid)):\n",
    "#        print(geneid)\n",
    "#        missing=(Request.replace(\"%%GENEID%%\",geneid))\n",
    "#        fout.write(missing+\"\\n\")\n",
    "    if (EnsemblToGeneNames.get(geneid)):\n",
    "#        RNASeqlistofgenes.append(GeneNamesToEnsembl[EnsemblToGeneNames[geneid]]) # a conversion Ensembl->Gene->Ensembl to get a unique Ensemble Id for a given gene name\n",
    "        RNASeqlistofgenes.append(geneid)\n",
    "#    else:\n",
    "#        eprint(\"Missing\",geneid)\n",
    "fd.close()\n",
    "\n",
    "#fout.close()\n",
    "\n",
    "\n",
    "# Table 6 : Drug targets\n",
    "fd=open(filenameKEGGDrugsGenes ,\"r\")\n",
    "\n",
    "lines = fd.readlines()\n",
    "\n",
    "Allmeds=dict()\n",
    "\n",
    "for l in lines:\n",
    "    t=l.split(\";\")\n",
    "    t[len(t)-1]=t[len(t)-1].replace(\"\\n\",\"\")\n",
    "    completeTargets=t[2].split('|')+t[3].replace(\"Enzyme:\",\"\").split(',')+t[4].split('|')\n",
    "    completeTargets=[x.strip().split(\" \")[0] for x in completeTargets if len(x)>2]\n",
    "    completeTargetsEnsembl=[GeneNamesToEnsembl.get(x) for x in completeTargets if (GeneNamesToEnsembl.get(x) != None)]\n",
    "    Allmeds[t[1].strip()]={'KeggId': t[0], 'TargetsGenes': completeTargets, 'TargetsGenesEnsembl': completeTargetsEnsembl }\n",
    "\n",
    "fd.close()\n",
    "\n",
    "# Table 6 : Mean Transcript length\n",
    "\n",
    "fd = open(filenameCorrespondanceEnsemblMeanLength,\"r\")\n",
    "\n",
    "lines=fd.readlines()\n",
    "\n",
    "AllGeneMeans = dict()\n",
    "for g in lines:\n",
    "    t=g.split(\";\")\n",
    "    t[1]=float(t[1].replace(\"\\n\",\"\"))\n",
    "    AllGeneMeans[t[0]]=t[1]\n",
    "    \n",
    "fd.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for g in EnsemblToGeneNamesList:\n",
    "    EnsemblToGeneNamesList[g]=list(set(EnsemblToGeneNamesList.get(g)))\n",
    "    EnsemblToGeneNamesList.get(g).sort()\n",
    "    if (len(EnsemblToGeneNamesList.get(g))>1):\n",
    "        print(g,EnsemblToGeneNamesList.get(g).sort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json, io\n",
    "\n",
    "# Read JSON file\n",
    "with open('../tables/Correspondance_Ensembl_GeneNames_by_SPARQL.json') as data_file:\n",
    "    genelist = json.load(data_file)\n",
    "\n",
    "\n",
    "GenenameToEnsembl=dict()\n",
    "for gid in genelist:\n",
    "    genename=genelist[gid][0]\n",
    "    if not (GenenameToEnsembl.get(genename)):\n",
    "        GenenameToEnsembl[genename]=list()\n",
    "        GenenameToEnsembl[genename].append(gid)\n",
    "\n",
    "GeneAltNameToName=dict()\n",
    "for gid in genelist:\n",
    "    genename=genelist[gid][0]\n",
    "    GeneAltNameToName[genename]=genename\n",
    "    for i in range(1,len(genelist[gid])):\n",
    "        GeneAltNameToName[genelist[gid][i]]=genename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction de la liste des cibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# étape 1 : construction du fichier d\\'association Reactions <-> EC numbers\\n\\neprint(\"Entering : Association RxN <-> Enzymes list construction\")\\n\\nSBMLfile = Param_SBMLfile\\n\\n#SBMLfile = raw_input(\"Enter the SBML filename ? \")\\n\\ndef ConstructAssociationList(SBMLfile, RXN_EC_file=\"/tmp/RXN_EC.txt\"):\\n\\n    import os\\n    os.system(\"../scripts/Construct_List_RXN_Enzymes.sh \"+SBMLfile+\" \"+RXN_EC_file)\\n    fd = open(RXN_EC_file,\"r\")\\n    lines = fd.readlines()\\n\\n    genes = dict()\\n    for l in lines:\\n        t=l.split(\" \")\\n        cum=\\'\\'\\n        for i in range(1,len(t)-1):\\n            cum=cum+t[i]+\" \"\\n        genes[t[0]]=cum\\n    return genes\\n\\ngenes=ConstructAssociationList(SBMLfile,RXN_EC_file)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Reconstruction\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# étape 1 : construction du fichier d'association Reactions <-> EC numbers\n",
    "\n",
    "eprint(\"Entering : Association RxN <-> Enzymes list construction\")\n",
    "\n",
    "SBMLfile = Param_SBMLfile\n",
    "\n",
    "#SBMLfile = raw_input(\"Enter the SBML filename ? \")\n",
    "\n",
    "def ConstructAssociationList(SBMLfile, RXN_EC_file=\"/tmp/RXN_EC.txt\"):\n",
    "\n",
    "    import os\n",
    "    os.system(\"../scripts/Construct_List_RXN_Enzymes.sh \"+SBMLfile+\" \"+RXN_EC_file)\n",
    "    fd = open(RXN_EC_file,\"r\")\n",
    "    lines = fd.readlines()\n",
    "\n",
    "    genes = dict()\n",
    "    for l in lines:\n",
    "        t=l.split(\" \")\n",
    "        cum=''\n",
    "        for i in range(1,len(t)-1):\n",
    "            cum=cum+t[i]+\" \"\n",
    "        genes[t[0]]=cum\n",
    "    return genes\n",
    "\n",
    "genes=ConstructAssociationList(SBMLfile,RXN_EC_file)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Etape 2 : Single Reaction Analysis\\n\\neprint(\"Entering : Single Reaction Analysis\")\\n\\n# perfoming a single_reaction_deletion analysis of the network\\n\\nmodel = cobra.io.read_sbml_model(SBMLfile)\\n\\n# the objective coefficient must be properly set\\nmodel.reactions.CancerBiomass_OF.objective_coefficient=1\\n\\n# reference biomass growth\\nfba=model.optimize().f\\n\\n# single reaction deletion analysis\\n\\n## DEBUG ONLY\\nbegin = timer()\\n## END DEBUG ONLY\\nif (Param_DoReconstruction):\\n    rates, status = cobra.flux_analysis.single_reaction_deletion(model,solver=whichsolver)\\n\\n## DEBUG ONLY\\nend = timer()\\neprint(\"Execution time (Single Reaction Analysis) = \",end-begin,\"seconds\")\\n## END DEBUG ONLY\\n\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Etape 2 : Single Reaction Analysis\n",
    "\n",
    "eprint(\"Entering : Single Reaction Analysis\")\n",
    "\n",
    "# perfoming a single_reaction_deletion analysis of the network\n",
    "\n",
    "model = cobra.io.read_sbml_model(SBMLfile)\n",
    "\n",
    "# the objective coefficient must be properly set\n",
    "model.reactions.CancerBiomass_OF.objective_coefficient=1\n",
    "\n",
    "# reference biomass growth\n",
    "fba=model.optimize().f\n",
    "\n",
    "# single reaction deletion analysis\n",
    "\n",
    "## DEBUG ONLY\n",
    "begin = timer()\n",
    "## END DEBUG ONLY\n",
    "if (Param_DoReconstruction):\n",
    "    rates, status = cobra.flux_analysis.single_reaction_deletion(model,solver=whichsolver)\n",
    "\n",
    "## DEBUG ONLY\n",
    "end = timer()\n",
    "eprint(\"Execution time (Single Reaction Analysis) = \",end-begin,\"seconds\")\n",
    "## END DEBUG ONLY\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n# Etape 3 : Extraction des enzymes régulateurs (nécessite étape 1 et 2)\\n\\ndef getRegulators(rates, percentage=1.1):\\n    regulators = dict()\\n\\n    cpt=0\\n    for r in rates:\\n        if (rates.get(r)<percentage*fba):\\n            if (genes.get(r)!=\\'\\'):\\n                # print(r,\\':\\',rates.get(r),\" \",genes.get(r))\\n                cpt=cpt+1\\n                l=genes.get(r).split(\\' \\')\\n                for i in l:\\n                    if (i != \\'\\'):\\n                        regulators[i]=1\\n    return regulators\\n\\nif (Param_DoReconstruction):\\n    regulators = getRegulators(rates, Param_Pourcentage)\\n    \\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\n",
    "# Etape 3 : Extraction des enzymes régulateurs (nécessite étape 1 et 2)\n",
    "\n",
    "def getRegulators(rates, percentage=1.1):\n",
    "    regulators = dict()\n",
    "\n",
    "    cpt=0\n",
    "    for r in rates:\n",
    "        if (rates.get(r)<percentage*fba):\n",
    "            if (genes.get(r)!=''):\n",
    "                # print(r,':',rates.get(r),\" \",genes.get(r))\n",
    "                cpt=cpt+1\n",
    "                l=genes.get(r).split(' ')\n",
    "                for i in l:\n",
    "                    if (i != ''):\n",
    "                        regulators[i]=1\n",
    "    return regulators\n",
    "\n",
    "if (Param_DoReconstruction):\n",
    "    regulators = getRegulators(rates, Param_Pourcentage)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Etape 4 : récupération de la liste de gènes régulateurs\\ndef GeneListFromEC(ecnumber):\\n    if (ecnumber.find(\\'-\\')>0):\\n        cum=list()\\n        for i in range(1,500):\\n            gl=ECTCDBToEnsembl.get(ecnumber.replace(\\'-\\',str(i)))\\n            if (gl != None and len(gl)>0):\\n                cum+=gl\\n        return cum\\n    else:\\n        gl=ECTCDBToEnsembl.get(ecnumber)\\n        if (gl == None):\\n            gl=list()\\n        return gl\\n\\nif (Param_DoReconstruction):\\n    TargetGenesEnsembl=list()\\n    for ec in regulators:\\n        TargetGenesEnsembl+=GeneListFromEC(ec.lower())\\n    \\n    TargetGenes = [EnsemblToGeneNames.get(x) for x in TargetGenesEnsembl]\\n    TargetGenes=list()\\n    for x in TargetGenesEnsembl:\\n        if (genelist.get(x)):\\n            TargetGenes.append(genelist.get(x)[0])\\n        else:\\n            eprint(\\'Missing \\',x)\\n    \\n    TargetGenes=set(TargetGenes)\\n    TargetGenes=list(TargetGenes)\\n    \\n    TargetGenesEnsembl=set(TargetGenesEnsembl)\\n    TargetGenesEnsembl=list(TargetGenesEnsembl)\\n    \\n    eprint(\"Target gene list size =\",len(TargetGenes))\\n    \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Etape 4 : récupération de la liste de gènes régulateurs\n",
    "def GeneListFromEC(ecnumber):\n",
    "    if (ecnumber.find('-')>0):\n",
    "        cum=list()\n",
    "        for i in range(1,500):\n",
    "            gl=ECTCDBToEnsembl.get(ecnumber.replace('-',str(i)))\n",
    "            if (gl != None and len(gl)>0):\n",
    "                cum+=gl\n",
    "        return cum\n",
    "    else:\n",
    "        gl=ECTCDBToEnsembl.get(ecnumber)\n",
    "        if (gl == None):\n",
    "            gl=list()\n",
    "        return gl\n",
    "\n",
    "if (Param_DoReconstruction):\n",
    "    TargetGenesEnsembl=list()\n",
    "    for ec in regulators:\n",
    "        TargetGenesEnsembl+=GeneListFromEC(ec.lower())\n",
    "    \n",
    "    TargetGenes = [EnsemblToGeneNames.get(x) for x in TargetGenesEnsembl]\n",
    "    TargetGenes=list()\n",
    "    for x in TargetGenesEnsembl:\n",
    "        if (genelist.get(x)):\n",
    "            TargetGenes.append(genelist.get(x)[0])\n",
    "        else:\n",
    "            eprint('Missing ',x)\n",
    "    \n",
    "    TargetGenes=set(TargetGenes)\n",
    "    TargetGenes=list(TargetGenes)\n",
    "    \n",
    "    TargetGenesEnsembl=set(TargetGenesEnsembl)\n",
    "    TargetGenesEnsembl=list(TargetGenesEnsembl)\n",
    "    \n",
    "    eprint(\"Target gene list size =\",len(TargetGenes))\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Regulatory network reconstruction using PathwayCommons SPARQL endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "# Algorithms\n",
    "\n",
    "Aliases = dict()\n",
    "for g in GeneAltNameToName:\n",
    "    if not Aliases.get(GeneAltNameToName.get(g)):\n",
    "        Aliases[GeneAltNameToName.get(g)] = list()\n",
    "    Aliases[GeneAltNameToName.get(g)].append(g)\n",
    "\n",
    "\n",
    "\n",
    "def GetTFControllers(EnsemblId):\n",
    "    commonPCPrefixes = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX bp3: <http://www.biopax.org/release/biopax-level3.owl#>\n",
    "PREFIX taxon: <http://identifiers.org/taxonomy/>\n",
    "PREFIX reactome: <http://identifiers.org/reactome/>\n",
    "PREFIX release: <http://www.reactome.org/biopax/49/48887#>\n",
    "\n",
    "PREFIX up: <http://purl.uniprot.org/core/> \n",
    "PREFIX uniprot: <http://purl.uniprot.org/uniprot/>\n",
    "PREFIX bp: <http://www.biopax.org/release/biopax-level3.owl#>\n",
    "PREFIX chebi: <http://purl.obolibrary.org/obo/CHEBI_>\n",
    "PREFIX obo2: <http://purl.obolibrary.org/obo#>\n",
    "\"\"\"\n",
    "\n",
    "    Request = \"\"\"\n",
    "SELECT ?tempReac ?type ?controlledName ?controllerName ?source WHERE{ \n",
    "    FILTER( (?controlledName = 'Transcription of %%GENETARGETNAME%%'^^<http://www.w3.org/2001/XMLSchema#string>)\n",
    "        and (?controllerName != '%%GENETARGETNAME%%')\n",
    "        and (?source != 'mirtarbase') ) .\n",
    "    ?tempReac a bp:TemplateReactionRegulation .\n",
    "    ?tempReac bp:displayName ?reacName ; \n",
    "        bp:controlled ?controlled ; \n",
    "        bp:controller ?controller ; \n",
    "        bp:controlType ?type ; \n",
    "        bp:dataSource ?source .\n",
    "    ?controlled bp:displayName ?controlledName .\n",
    "    ?controller bp:displayName ?controllerName . }\n",
    "GROUP BY ?controlledName ?controllerName\n",
    "\"\"\"\n",
    "    RequestToBePerformed=commonPCPrefixes+Request.replace(\"%%GENETARGETNAME%%\",EnsemblId)\n",
    "    sparql = SPARQLWrapper(PC_Endpoint)\n",
    "    sparql.setQuery(RequestToBePerformed)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    query = sparql.query().convert()\n",
    "    results=list()\n",
    "    listofgenes=list()\n",
    "    ListBindings=query.get('results').get('bindings')\n",
    "    for l in ListBindings:\n",
    "        controllerName = (l.get('controllerName').get('value'))\n",
    "        controlType= (l.get('type').get('value'))\n",
    "        rule = controllerName+\"_\"+controlType+\"_\"+EnsemblId\n",
    "        if (rule not in results):\n",
    "            results.append(rule)\n",
    "        if (controllerName not in listofgenes):\n",
    "            listofgenes.append(controllerName)\n",
    "    return results,listofgenes\n",
    "\n",
    "def getParentGraph(l,limit=30):\n",
    "    i=0\n",
    "    allgenes=dict()\n",
    "    for g in l:\n",
    "        allgenes[g]=1\n",
    "    listofrelations=list()\n",
    "    unmapped=list()\n",
    "    while (i<len(l) and i<limit):\n",
    "        gene=l[i]\n",
    "        L=Aliases.get(GeneAltNameToName.get(gene))\n",
    "        relations=list()\n",
    "        newgenes=list()\n",
    "        for g in L:\n",
    "            a,b=GetTFControllers(g)\n",
    "            relations=relations+a\n",
    "            newgenes=newgenes+b\n",
    "        \n",
    "        relations=list(set(relations))\n",
    "        newgenes=list(set(newgenes))\n",
    "#        relations,newgenes = GetTFControllers(GeneAltNameToName.get(gene))\n",
    "        if (len(relations) == 0):\n",
    "            unmapped.append(gene)\n",
    "        listofrelations+=relations\n",
    "        for g in newgenes:\n",
    "            if (allgenes.get(g) != 1): # (g not in l):\n",
    "                l.append(g)\n",
    "                allgenes[g]=1\n",
    "        i+=1\n",
    "    return listofrelations,l,unmapped\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Improved version\n",
    "\n",
    "def GetTFControllersList(EnsemblId):\n",
    "    commonPCPrefixes = \"\"\"\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX dc: <http://purl.org/dc/elements/1.1/>\n",
    "PREFIX dcterms: <http://purl.org/dc/terms/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "PREFIX skos: <http://www.w3.org/2004/02/skos/core#>\n",
    "PREFIX bp3: <http://www.biopax.org/release/biopax-level3.owl#>\n",
    "PREFIX taxon: <http://identifiers.org/taxonomy/>\n",
    "PREFIX reactome: <http://identifiers.org/reactome/>\n",
    "PREFIX release: <http://www.reactome.org/biopax/49/48887#>\n",
    "\n",
    "PREFIX up: <http://purl.uniprot.org/core/> \n",
    "PREFIX uniprot: <http://purl.uniprot.org/uniprot/>\n",
    "PREFIX bp: <http://www.biopax.org/release/biopax-level3.owl#>\n",
    "PREFIX chebi: <http://purl.obolibrary.org/obo/CHEBI_>\n",
    "PREFIX obo2: <http://purl.obolibrary.org/obo#>\n",
    "\"\"\"\n",
    "\n",
    "    Request = \"\"\"\n",
    "SELECT ?tempReac ?type ?controlledName ?controllerName ?source WHERE{ \n",
    "    FILTER(\n",
    "    (\"\"\"\n",
    "    for i in range(0,len(EnsemblId)-1):\n",
    "        Request=Request+\"\"\"(?controlledName = 'Transcription of %%GENETARGETNAME%%'^^<http://www.w3.org/2001/XMLSchema#string>) or \n",
    "        \"\"\".replace(\"%%GENETARGETNAME%%\",EnsemblId[i])\n",
    "    Request=Request+\"(?controlledName = 'Transcription of %%GENETARGETNAME%%'^^<http://www.w3.org/2001/XMLSchema#string>)\".replace(\"%%GENETARGETNAME%%\",EnsemblId[len(EnsemblId)-1])\n",
    "    Request=Request+\"\"\")\n",
    "        and (?controllerName != '%%GENETARGETNAME%%')\n",
    "        and (?source != 'mirtarbase') ) .\n",
    "    ?tempReac a bp:TemplateReactionRegulation .\n",
    "    ?tempReac bp:displayName ?reacName ; \n",
    "        bp:controlled ?controlled ; \n",
    "        bp:controller ?controller ; \n",
    "        bp:controlType ?type ; \n",
    "        bp:dataSource ?source .\n",
    "    ?controlled bp:displayName ?controlledName .\n",
    "    ?controller bp:displayName ?controllerName . }\n",
    "GROUP BY ?controlledName ?controllerName\n",
    "\"\"\"\n",
    "#    print(Request)\n",
    "#    RequestToBePerformed=commonPCPrefixes+Request.replace(\"%%GENETARGETNAME%%\",EnsemblId)\n",
    "    RequestToBePerformed=commonPCPrefixes+Request\n",
    "    sparql = SPARQLWrapper(PC_Endpoint)\n",
    "    sparql.setQuery(RequestToBePerformed)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    sparql.setMethod(\"POST\")\n",
    "    query = sparql.query().convert()\n",
    "    results=list()\n",
    "    listofgenes=list()\n",
    "    ListBindings=query.get('results').get('bindings')\n",
    "    for l in ListBindings:\n",
    "        controllerName = (l.get('controllerName').get('value'))\n",
    "        controlType= (l.get('type').get('value'))\n",
    "        controlledGene=(l.get('controlledName').get('value')).replace(\"Transcription of \",\"\")\n",
    "        rule = controllerName+\"_\"+controlType +\"_\"+GeneAltNameToName.get(controlledGene)\n",
    "        if (rule not in results):\n",
    "            results.append(rule)\n",
    "        if (controllerName not in listofgenes):\n",
    "            listofgenes.append(controllerName)\n",
    "    return results,listofgenes\n",
    "\n",
    "def getParentGraphList(l,limit=30):\n",
    "    pas=100\n",
    "    i=0\n",
    "    allgenes=dict()\n",
    "    for g in l:\n",
    "        allgenes[g]=1\n",
    "    listofrelations=list()\n",
    "    unmapped=list()\n",
    "    while (i<len(l) and i<limit):\n",
    "        eprint(\"Treated \",i,\" genes, still \",(len(l)-i),\" limit = \",limit)\n",
    "        L=list()\n",
    "        for j in range(0,pas):\n",
    "            if (i+j<len(l)):\n",
    "                gene=l[i+j]\n",
    "                L=L+Aliases.get(GeneAltNameToName.get(gene))\n",
    "        relations,newgenes=GetTFControllersList(L)\n",
    "        if (len(relations) == 0):\n",
    "            unmapped.append(gene)\n",
    "        listofrelations+=relations\n",
    "        for g in newgenes:\n",
    "            g=GeneAltNameToName.get(g)\n",
    "            if (g not in l): #(allgenes.get(g) != 1): # \n",
    "                l.append(g)\n",
    "                allgenes[g]=1\n",
    "        i+=pas\n",
    "    return listofrelations,l,unmapped\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\neprint(\"Entering : RRG reconstruction\")\\n\\n\\n## DEBUG ONLY\\nbegin = timer()\\n## END DEBUG ONLY\\n\\nif (Param_DoReconstruction):\\n    TargetGenesName = TargetGenes #[EnsemblToGeneNames.get(x) for x in TargetGenes if (len(x) > 2)]\\n    \\n    a,b,u=getParentGraphList(TargetGenesName,50000)\\n    \\n    ## DEBUG ONLY\\n    end = timer()\\n    eprint(\"Execution time for RRG reconstruction = \",end-begin,\"seconds\")\\n    ## END DEBUG ONLY\\n    \\n    eprint(\\'Reconstructed graph contains\\',len(b),\\'genes,\\',len(a),\\'interactions,\\',\\'with\\',len(u),\\'unmapped genes.\\')\\n    \\n    \\n    # write the file for compatibility purpose\\n    \\n    fd = open(Param_RRGFilename,\"w\")\\n    for r in a:\\n        relation=r.split(\"_\")\\n        if (relation[1] != \"ACTIVATION\"):\\n            eprint(relation)\\n        fd.write(relation[0]+\";\"+relation[2]+\"\\n\")\\n    fd.close()\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "eprint(\"Entering : RRG reconstruction\")\n",
    "\n",
    "\n",
    "## DEBUG ONLY\n",
    "begin = timer()\n",
    "## END DEBUG ONLY\n",
    "\n",
    "if (Param_DoReconstruction):\n",
    "    TargetGenesName = TargetGenes #[EnsemblToGeneNames.get(x) for x in TargetGenes if (len(x) > 2)]\n",
    "    \n",
    "    a,b,u=getParentGraphList(TargetGenesName,50000)\n",
    "    \n",
    "    ## DEBUG ONLY\n",
    "    end = timer()\n",
    "    eprint(\"Execution time for RRG reconstruction = \",end-begin,\"seconds\")\n",
    "    ## END DEBUG ONLY\n",
    "    \n",
    "    eprint('Reconstructed graph contains',len(b),'genes,',len(a),'interactions,','with',len(u),'unmapped genes.')\n",
    "    \n",
    "    \n",
    "    # write the file for compatibility purpose\n",
    "    \n",
    "    fd = open(Param_RRGFilename,\"w\")\n",
    "    for r in a:\n",
    "        relation=r.split(\"_\")\n",
    "        if (relation[1] != \"ACTIVATION\"):\n",
    "            eprint(relation)\n",
    "        fd.write(relation[0]+\";\"+relation[2]+\"\\n\")\n",
    "    fd.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entering : Graph Filtering\n",
      "Remove  142 genes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Construction and filter\n",
    "eprint(\"Entering : Graph Filtering\")\n",
    "\n",
    "RNASeqList=dict()\n",
    "for g in RNASeqlistofgenes:\n",
    "    L=GeneNamesToEnsemblList.get(EnsemblToGeneNames[g])\n",
    "    if L:\n",
    "        for l in L:\n",
    "            RNASeqList[l]=1\n",
    "\n",
    "\n",
    "GenesToBeRemoved=list()\n",
    "\n",
    "filename = Param_RRGFilename\n",
    "\n",
    "genesingraph = dict()\n",
    "listofgenes = list()\n",
    "listofinteractions = list()\n",
    "listofinteractionsNamed = list()\n",
    "\n",
    "fd = open(filename,\"r\")\n",
    "\n",
    "lines = fd.readlines()\n",
    "geneid=0\n",
    "for l in lines:\n",
    "    t=l.split(\";\")\n",
    "    t[1]=t[1].replace(\"\\n\",\"\")\n",
    "#    if (GeneNamesToEnsembl[t[0]] in RNASeqlistofgenes and GeneNamesToEnsembl[t[1]] in RNASeqlistofgenes):\n",
    "    if (RNASeqList.get(GeneNamesToEnsembl[t[0]]) and RNASeqList.get(GeneNamesToEnsembl[t[1]])):\n",
    "        if (not (GeneNamesToEnsembl[t[0]] in GenesToBeRemoved or GeneNamesToEnsembl[t[1]] in GenesToBeRemoved)):\n",
    "            if (listofgenes.count(GeneNamesToEnsembl[t[0]]) == 0):\n",
    "                listofgenes.append(GeneNamesToEnsembl[t[0]])\n",
    "                genesingraph[GeneNamesToEnsembl[t[0]]]=len(listofgenes)-1\n",
    "            if (listofgenes.count(GeneNamesToEnsembl[t[1]]) == 0):\n",
    "                listofgenes.append(GeneNamesToEnsembl[t[1]])\n",
    "                genesingraph[GeneNamesToEnsembl[t[1]]]=len(listofgenes)-1\n",
    "            listofinteractions.append((genesingraph[GeneNamesToEnsembl[t[0]]],genesingraph[GeneNamesToEnsembl[t[1]]]))\n",
    "            listofinteractionsNamed.append((GeneNamesToEnsembl[t[0]],GeneNamesToEnsembl[t[1]]))\n",
    "    else:\n",
    "        eprint(\"Warning : \",GeneNamesToEnsembl[t[0]],\"or\",GeneNamesToEnsembl[t[1]],\"isn't in RNASeq\",)\n",
    "\n",
    "fd.close()\n",
    "\n",
    "\n",
    "\n",
    "# It is required to remove cycles and loops in the graph.\n",
    "# Here is a greedy method\n",
    "\n",
    "listofinteractionsNamedClean = list()\n",
    "\n",
    "RRG = nx.DiGraph()\n",
    "for t in listofinteractionsNamed:\n",
    "#    if True:\n",
    "    if not((RRG.has_node(t[0]) and RRG.has_node(t[1]) and (RRG.has_edge(t[1],t[0]) or nx.has_path(RRG,t[1],t[0])))):\n",
    "        RRG.add_edge(t[0],t[1])\n",
    "        listofinteractionsNamedClean.append((t[0],t[1]))\n",
    "\n",
    "globalmax=100\n",
    "nbRemovedGenes=0\n",
    "\n",
    "while (globalmax>Param_MaxIndegreeInRRG):\n",
    "    T=RRG.in_degree()\n",
    "    Tout=RRG.out_degree()\n",
    "    vmax=-1\n",
    "    globalmax=-1\n",
    "    keymax = \"\"\n",
    "    for g in T:\n",
    "        v=T.get(g)\n",
    "        if (v>vmax and Tout.get(g)>0):\n",
    "            vmax=v\n",
    "            keymax = g\n",
    "        if (v>globalmax):\n",
    "            globalmax=v\n",
    "    #print(\"Remove gene \",keymax, \"having an in degree equal to\",vmax)\n",
    "    GenesToBeRemoved.append(keymax)\n",
    "    nbRemovedGenes+=1\n",
    "    RRG.remove_node(keymax)\n",
    "eprint(\"Remove \",nbRemovedGenes,\"genes\")\n",
    "\n",
    "filename = Param_RRGFilename\n",
    "\n",
    "genesingraph = dict()\n",
    "listofgenes = list()\n",
    "listofinteractions = list()\n",
    "listofinteractionsNamed = list()\n",
    "\n",
    "fd = open(filename,\"r\")\n",
    "\n",
    "lines = fd.readlines()\n",
    "geneid=0\n",
    "for l in lines:\n",
    "    t=l.split(\";\")\n",
    "    t[1]=t[1].replace(\"\\n\",\"\")\n",
    "#    if (GeneNamesToEnsembl[t[0]] in RNASeqlistofgenes and GeneNamesToEnsembl[t[1]] in RNASeqlistofgenes):\n",
    "#    if (RNASeqList.get(GeneNamesToEnsembl[t[0]]) and RNASeqList.get(GeneNamesToEnsembl[t[1]])):\n",
    "    if (RNASeqList.get(GeneNamesToEnsembl[t[0]]) and RNASeqList.get(GeneNamesToEnsembl[t[1]])):\n",
    "        if (not (GeneNamesToEnsembl[t[0]] in GenesToBeRemoved or GeneNamesToEnsembl[t[1]] in GenesToBeRemoved)):\n",
    "            if (listofgenes.count(GeneNamesToEnsembl[t[0]]) == 0):\n",
    "                listofgenes.append(GeneNamesToEnsembl[t[0]])\n",
    "                genesingraph[GeneNamesToEnsembl[t[0]]]=len(listofgenes)-1\n",
    "            if (listofgenes.count(GeneNamesToEnsembl[t[1]]) == 0):\n",
    "                listofgenes.append(GeneNamesToEnsembl[t[1]])\n",
    "                genesingraph[GeneNamesToEnsembl[t[1]]]=len(listofgenes)-1\n",
    "            listofinteractions.append((genesingraph[GeneNamesToEnsembl[t[0]]],genesingraph[GeneNamesToEnsembl[t[1]]]))\n",
    "            listofinteractionsNamed.append((GeneNamesToEnsembl[t[0]],GeneNamesToEnsembl[t[1]]))\n",
    "\n",
    "fd.close()\n",
    "\n",
    "# It is required to remove to cycles and loops in the graph.\n",
    "# Here is a greedy method\n",
    "\n",
    "listofinteractionsNamedClean = list()\n",
    "\n",
    "RRG = nx.DiGraph()\n",
    "for t in listofinteractionsNamed:\n",
    "    if not((RRG.has_node(t[0]) and RRG.has_node(t[1]) and (RRG.has_edge(t[1],t[0]) or nx.has_path(RRG,t[1],t[0])))):\n",
    "        RRG.add_edge(t[0],t[1])\n",
    "        listofinteractionsNamedClean.append((t[0],t[1]))\n",
    "#    else:\n",
    "#        print(\"Boucle si ajout de %s -> %s\" % (t[0],t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entering : Bayesian model Skeleton Construction\n",
      "Execution time (Bayesian model Skeleton Construction) =  0.08160417401813902 seconds\n"
     ]
    }
   ],
   "source": [
    "# Building the Bayesian model (from listofinteractionsNamedClean)\n",
    "\n",
    "eprint(\"Entering : Bayesian model Skeleton Construction\")\n",
    "\n",
    "## DEBUG ONLY\n",
    "begin = timer()\n",
    "## END DEBUG ONLY\n",
    "\n",
    "\n",
    "\n",
    "model = BayesianModel(listofinteractionsNamedClean)\n",
    "\n",
    "\n",
    "\n",
    "## DEBUG ONLY\n",
    "end = timer()\n",
    "eprint(\"Execution time (Bayesian model Skeleton Construction) = \",end-begin,\"seconds\")\n",
    "## END DEBUG ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# basic optimization (use of a hash table to know if a gene is in the RRG)\n",
    "GeneDict=dict()\n",
    "\n",
    "for g in listofgenes:\n",
    "    L=GeneNamesToEnsemblList.get(EnsemblToGeneNames[g])\n",
    "    if L:\n",
    "        for l in L:\n",
    "            GeneDict[l]=g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNASeq Data integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entering : RNASeq data discretization\n",
      "Execution time (RNASeq data discretization) =  33.879915852012346 seconds\n"
     ]
    }
   ],
   "source": [
    "# Reading the datafile (RNA-seq normalized with DESeq2)\n",
    "\n",
    "eprint(\"Entering : RNASeq data discretization\")\n",
    "\n",
    "\n",
    "## DEBUG ONLY\n",
    "begin = timer()\n",
    "## END DEBUG ONLY\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filename = Param_RNASeqFilename\n",
    "\n",
    "data = dict()\n",
    "\n",
    "TumoralConditions=list()\n",
    "NormalConditions=list()\n",
    "\n",
    "fd = open(filename,\"r\")\n",
    "\n",
    "l=fd.readline()\n",
    "l=l.replace('\"','').replace('\\n','')\n",
    "t=l.split(\",\")\n",
    "\n",
    "for i in range(1,len(t)):\n",
    "    if (t[i][0:2] == \"CT\"):\n",
    "        TumoralConditions.append(i)\n",
    "    if (t[i][0:2] == \"CN\"):\n",
    "        NormalConditions.append(i)\n",
    "\n",
    "# à résoudre: il y a des gènes dans le graphe qui ne sont pas dans les données... Arrrgh\n",
    "\n",
    "raw_data=np.random.randint(low=0, high=1, size=(len(TumoralConditions),len(listofgenes)))\n",
    "#raw_data=np.random.randint(low=0, high=1, size=(len(NormalConditions),len(listofgenes)))\n",
    "\n",
    "sortedlistofgenes=list()\n",
    "# allgenes=list()\n",
    "\n",
    "for l in fd:\n",
    "    l=l.replace('\"','').replace('\\n','')\n",
    "    t=l.split(\",\")\n",
    "    NormalValues = [log(0.0001+float(t[x])) for x in NormalConditions]\n",
    "#    NormalValues=np.array(len(NormalConditions))\n",
    "#    for j in range(len(NormalConditions)):\n",
    "#        NormalValues[j]=t[NormalConditions[j]]\n",
    "    NormalMean=np.mean(NormalValues)\n",
    "    NormalStd=np.std(NormalValues)\n",
    "    geneid=t[0].split(\".\")[0]\n",
    "    BinarizedValues=[Binarized(float(t[x]),NormalMean,NormalStd,geneid) for x in TumoralConditions]\n",
    "    #if (GeneDict.get(geneid) == 1):\n",
    "    #        print(geneid,sum(BinarizedValues))\n",
    "    #if (geneid in listofgenes):\n",
    "    if (GeneDict.get(geneid)):\n",
    "        raw_data[:,len(sortedlistofgenes)]=BinarizedValues\n",
    "        sortedlistofgenes.append(GeneDict.get(geneid))\n",
    "\n",
    "    #print(t[0].split(\".\")[0],BinarizedValues)\n",
    "\n",
    "fd.close()\n",
    "\n",
    "data = pd.DataFrame(raw_data, columns=sortedlistofgenes)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## DEBUG ONLY\n",
    "end = timer()\n",
    "eprint(\"Execution time (RNASeq data discretization) = \",end-begin,\"seconds\")\n",
    "## END DEBUG ONLY\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entering : Bayesian Network fitting with RNASeq data\n",
      "Execution time (Bayesian Network fitting with RNASeq data) =  6.312621899996884 seconds\n"
     ]
    }
   ],
   "source": [
    "# Fitting the BN with data\n",
    "\n",
    "eprint(\"Entering : Bayesian Network fitting with RNASeq data\")\n",
    "\n",
    "## DEBUG ONLY\n",
    "begin = timer()\n",
    "## END DEBUG ONLY\n",
    "\n",
    "model.fit(data, estimator=BayesianEstimator, prior_type='K2',equivalent_sample_size=5)\n",
    "\n",
    "## DEBUG ONLY\n",
    "end = timer()\n",
    "eprint(\"Execution time (Bayesian Network fitting with RNASeq data) = \",end-begin,\"seconds\")\n",
    "## END DEBUG ONLY\n",
    "\n",
    "# saving the Bayesian Network for further use\n",
    "if (must_save_bif):\n",
    "    writer = BIFWriter(model)\n",
    "    writer.write_bif(filename=BIF_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Querying the Bayesian Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def getEvidence(medname):\n",
    "    listgenes = Allmeds.get(medname).get(\"TargetsGenesEnsembl\")\n",
    "    evidences = [State(x, 0) for x in listgenes if x in RRG.nodes()]\n",
    "    return evidences\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pgmpy\n",
    "pgmpy.estimators.BayesianEstimator.get_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# An alternative way is to perform a Bayesian Sampling of the BN\n",
    "\n",
    "eprint(\"Entering : Querying the Bayesian Network\")\n",
    "\n",
    "from pgmpy.readwrite import BIFReader\n",
    "model = BIFReader(filename=BIF_file)\n",
    "\n",
    "\n",
    "## DEBUG ONLY\n",
    "begin = timer()\n",
    "## END DEBUG ONLY\n",
    "\n",
    "inference = BayesianModelSampling(model)\n",
    "## DEBUG ONLY\n",
    "end = timer()\n",
    "eprint(\"Execution time, first part of Querying the Bayesian Network = \",end-begin,\"seconds\")\n",
    "## END DEBUG ONLY\n",
    "\n",
    "\n",
    "Number_of_samples = Param_NumberOfSample\n",
    "\n",
    "# NB evidences should be read somewhere\n",
    "evidences = getEvidence(Param_Drug)\n",
    "\n",
    "\n",
    "## DEBUG ONLY\n",
    "begin = timer()\n",
    "## END DEBUG ONLY\n",
    "\n",
    "samples=inference.likelihood_weighted_sample(evidences, Number_of_samples)\n",
    "#samples=inference.rejection_sample(evidences, Number_of_samples)\n",
    "\n",
    "\n",
    "## DEBUG ONLY\n",
    "end = timer()\n",
    "eprint(\"Execution time, second part (Querying the Bayesian Network) = \",end-begin,\"seconds\")\n",
    "## END DEBUG ONLY\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# get all the marginal probabilities for that evidence\n",
    "allMarginalProb=dict()\n",
    "for g in sortedlistofgenes:\n",
    "    #print(g,\" p0=\",samples[g].eq(0).sum()/Number_of_samples,\" p1=\",samples[g].eq(1).sum()/Number_of_samples,\" p2=\",samples[g].eq(2).sum()/Number_of_samples)\n",
    "    allMarginalProb[g]=[samples[g].eq(0).sum()/Number_of_samples,samples[g].eq(1).sum()/Number_of_samples,samples[g].eq(2).sum()/Number_of_samples]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Correspondance Reaction <-> Enzymes\n",
    "filename = RXN_EC_file\n",
    "\n",
    "ReactionsToEnsembl = dict()\n",
    "\n",
    "fd = open(filename,\"r\")\n",
    "\n",
    "lines = fd.readlines()\n",
    "for l in lines:\n",
    "    t=l.split(\" \")\n",
    "    RXN = t[0]\n",
    "    t[len(t)-1]=t[len(t)-1].replace(\"\\n\",\"\")\n",
    "    ReactionsToEnsembl[RXN]=list()\n",
    "    for i in range(1,len(t)):\n",
    "        val = ECTCDBToEnsembl.get(t[i].lower())\n",
    "        if (val != None):\n",
    "            ReactionsToEnsembl[RXN]+=val\n",
    "fd.close()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def ProbaReaction(L):\n",
    "    global allMarginalProb\n",
    "    maximum=0\n",
    "    minimum=1000    \n",
    "    for l in L:\n",
    "        if allMarginalProb.get(l):\n",
    "            minimum=min([minimum,1-allMarginalProb.get(l)[0]])\n",
    "            maximum=max([maximum,1-allMarginalProb.get(l)[0]])\n",
    "    if minimum==1000:\n",
    "        return \"1;1\"\n",
    "    else:\n",
    "        return str(minimum)+\";\"+str(maximum)\n",
    "\n",
    "def ProbaReactionAll(L):\n",
    "    global allMarginalProb\n",
    "    res=list()\n",
    "    for l in L:\n",
    "        if allMarginalProb.get(l):\n",
    "#            minimum=min([minimum,1-allMarginalProb.get(l)[0]])\n",
    "#            maximum=max([maximum,1-allMarginalProb.get(l)[0]])\n",
    "            res.append(1-allMarginalProb.get(l)[0])\n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "# Output the reactions probabilities\n",
    "\n",
    "output=open(Param_ProbaReactionsFilename,\"w\")\n",
    "\n",
    "for r in ReactionsToEnsembl:\n",
    "    if (len(ReactionsToEnsembl.get(r))>0):\n",
    "        output.write(str(r)+\";\"+str(ProbaReaction(ReactionsToEnsembl.get(r)))+\"\\n\")\n",
    "output.close()\n",
    "\n",
    "# Output the reactions probabilities (all)\n",
    "\n",
    "output=open(Param_ProbaReactionsFilename+\"ALL\",\"w\")\n",
    "\n",
    "for r in ReactionsToEnsembl:\n",
    "    if (len(ReactionsToEnsembl.get(r))>0):\n",
    "        output.write(str(r)+\";\"+str(ProbaReactionAll(ReactionsToEnsembl.get(r))).replace(\",\",\";\")+\"\\n\")\n",
    "output.close()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ComputeProbas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière partie, calcul de la nouvelle biomasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# To be very efficient, the long formal expressions must be reconstructed in a clever way\n",
    "\n",
    "def ExpressionFromList_rec(L,a,b):\n",
    "    #print(L,a,b)\n",
    "    if (b == a):\n",
    "        #print(\"Adding\",0)\n",
    "        return 0\n",
    "    else:\n",
    "        if (b-a == 1):\n",
    "            #print(\"Adding L[\"+str(a)+\"]\",L[a])\n",
    "            return L[a]\n",
    "        else:\n",
    "            milieu = int((a+b)/2)\n",
    "            return ExpressionFromList_rec(L,a,milieu)+ExpressionFromList_rec(L,milieu,b)\n",
    "\n",
    "def ExpressionFromList(L):\n",
    "    return ExpressionFromList_rec(L,0,len(L))\n",
    "\n",
    "\n",
    "def CobraModelToPROMOptLangModel(model,Prob,lambd=-1.0,usedsolver=\"cglpk\"):\n",
    "    epsilon = 1e-10\n",
    "    myoptmodel = optlang.Model(name = \"test\")\n",
    "    # first of all, performs a FVA analysis\n",
    "    eprint(\"Performing a FVA analysis\")\n",
    "    currenttime=timer()\n",
    "    fva0=flux_variability_analysis(model,fraction_of_optimum=0.001,solver=usedsolver)\n",
    "    fva=flux_variability_analysis(model,fraction_of_optimum=0.99,solver=usedsolver)\n",
    "    eprint(\"Finishing the FVA analysis in\",timer()-currenttime,\"seconds\")\n",
    "\n",
    "\n",
    "    obj=0\n",
    "    ListObjective=list()\n",
    "\n",
    "    Allvariables = list()\n",
    "    Alphavariables = list()\n",
    "    Betavariables = list()\n",
    "\n",
    "    AdditionalConstraints = list()\n",
    "    i=0\n",
    "    currenttime=timer()\n",
    "    \n",
    "    \n",
    "    for r in model.reactions:\n",
    "        if (i % 100 == 0):\n",
    "            eprint(\"Creating\",i,\"variables in\",timer()-currenttime,\"seconds\")\n",
    "            currenttime=timer()\n",
    "        i+=1\n",
    "\n",
    "        #v=optlang.Variable(r.id,lb=r.lower_bound,ub=r.upper_bound)\n",
    "        v=optlang.Variable(r.id,lb=fva0.get(r.id).get('minimum')-epsilon,ub=fva0.get(r.id).get('maximum')+epsilon)     \n",
    "        # v=optlang.Variable(r.id,lb=-2000,ub=2000)\n",
    "        Allvariables.append(v)\n",
    "\n",
    "        # alpha_i and beta_i\n",
    "        pi = Prob.get(r.id) # now a vector of [min,max] probabilities\n",
    "        if not pi:\n",
    "            pi = [1,1]\n",
    "        if (pi[0]<0.99):        \n",
    "            alpha=optlang.Variable('alpha_'+r.id,lb=0,ub=100000)\n",
    "            beta=optlang.Variable('beta_'+r.id,lb=0,ub=100000)\n",
    "            Alphavariables.append(alpha)\n",
    "            Betavariables.append(beta)\n",
    "            # contributions of alpha and beta to the objective = lambda * (alpha+beta) with lambda = -1\n",
    "            #obj = obj + lambd * alpha + lambd * beta\n",
    "            ListObjective.append(lambd * alpha)\n",
    "            ListObjective.append(lambd * beta)\n",
    "            \n",
    "            AdditionalConstraints.append(optlang.Constraint(v+alpha,lb=pi[1]*fva.get(r.id).get('minimum'),ub=2000))\n",
    "            AdditionalConstraints.append(optlang.Constraint(v-beta,lb=-2000,ub=pi[0]*fva.get(r.id).get('maximum')))\n",
    "\n",
    "        if r.objective_coefficient != 0:\n",
    "            # obj = obj + r.objective_coefficient * v\n",
    "            ListObjective.append(r.objective_coefficient * v)\n",
    "\n",
    "    \n",
    "    currenttime=timer()\n",
    "    eprint(\"Reconstructing Objective\")\n",
    "#    for o in ListObjective:\n",
    "#        obj=obj+o\n",
    "    obj = ExpressionFromList(ListObjective)\n",
    "    eprint(\"Reconstructing Objective in\",timer()-currenttime,\"seconds\")\n",
    "    \n",
    "    AllConstraints = list()\n",
    "    i=0\n",
    "    currenttime=timer()\n",
    "    for m in model.metabolites:\n",
    "        if (i % 100 == 0):\n",
    "            eprint(\"Creating\",i,\"constraints in\",timer()-currenttime,\"seconds\")\n",
    "            currenttime=timer()\n",
    "        i+=1\n",
    "        C=list()\n",
    "        for r in m.reactions:\n",
    "            C.append(r.get_coefficient(m)*Allvariables[model.reactions.index(r)])\n",
    "        AllConstraints.append(optlang.Constraint(ExpressionFromList(C),lb=0,ub=0))\n",
    "\n",
    "    eprint(\"Adding Allvariables\")\n",
    "    myoptmodel.add(Allvariables)\n",
    "    eprint(\"Adding Alphavariables\")\n",
    "    myoptmodel.add(Alphavariables)\n",
    "    eprint(\"Adding Betavariables\")\n",
    "    myoptmodel.add(Betavariables)\n",
    "    eprint(\"Adding AllConstraints\")\n",
    "    myoptmodel.add(AllConstraints)\n",
    "    eprint(\"Adding AdditionalConstraints\")\n",
    "    myoptmodel.add(AdditionalConstraints)\n",
    "    myoptmodel.objective = optlang.Objective(obj, direction=\"max\")\n",
    "    return myoptmodel\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# on recharge les probabilités des réactions pour des problèmes de compatibilités\n",
    "\n",
    "filename = Param_ProbaReactionsFilename\n",
    "fd=open(filename,\"r\")\n",
    "\n",
    "ProbaReaction=dict()\n",
    "\n",
    "lines = fd.readlines()\n",
    "\n",
    "for l in lines:\n",
    "    t=l.split(\";\")\n",
    "    t[1]=t[1].replace(\"\\n\",\"\")\n",
    "    ProbaReaction[t[0]]=[float(t[1]),float(t[2])]\n",
    "\n",
    "fd.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# on recharge le modèle cobra\n",
    "mcancer = cobra.io.read_sbml_model(Param_SBMLfile)\n",
    "mcancer.reactions.CancerBiomass_OF.objective_coefficient = 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Creation du modèle PROM sous optlang\n",
    "begin = timer()\n",
    "mProm=CobraModelToPROMOptLangModel(mcancer,ProbaReaction,usedsolver=whichsolver)\n",
    "end = timer()\n",
    "\n",
    "eprint(\"Execution time (PROM Model creation) =\",end-begin,\"seconds\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Compares glpk and gurobi\n",
    "if debugon:\n",
    "    import gurobipy\n",
    "\n",
    "    lp = mProm.to_lp()\n",
    "    lpfilename = Param_SBMLfileBN.replace(\".xml\",\".lp\")\n",
    "    fd=open(lpfilename,\"w\")\n",
    "    fd.write(lp)\n",
    "    fd.close()\n",
    "\n",
    "    mPromGurobi = gurobipy.read(lpfilename)\n",
    "    \n",
    "    begin = timer()\n",
    "    res=mPromGurobi.optimize()\n",
    "    eprint(\"Gurobi\",timer()-begin,\"seconds, biomass=\",mPromGurobi.getVarByName(\"CancerBiomass_OF\").X)\n",
    "\n",
    "\n",
    "    begin = timer()\n",
    "    res=mProm.optimize()\n",
    "    eprint(\"glpk\",timer()-begin,\"seconds, biommass=\",mProm.variables.CancerBiomass_OF.primal)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Optimisation\n",
    "begin = timer()\n",
    "mProm.optimize()\n",
    "end = timer()\n",
    "\n",
    "eprint(\"Execution time (PROM Optimization) =\",end-begin,\"seconds\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Results\n",
    "eprint(\"Objective value = \",mProm.objective.value)\n",
    "print(\"Biomass = \",mProm.variables.CancerBiomass_OF.primal)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import PROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "endtotal = timer()\n",
    "eprint(\"Execution completed in\",endtotal-begintotal,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
