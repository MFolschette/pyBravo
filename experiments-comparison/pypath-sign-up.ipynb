{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upstream signaling network reconstruction\n",
    "===============================\n",
    "\n",
    "The following code use [pyPath library](https://github.com/saezlab/pypath) to reconstruct signaling network from a list of biological entities (csv format) and querying [OmnipathDB](http://omnipathdb.org/).\n",
    "\n",
    "## 1. Load function\n",
    "\n",
    "Import modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import pypath\n",
    "from pypath import curl\n",
    "from pypath import data_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upstream_signaling(pa, max_depth, to_be_explore, already_explored=[], current_depth=0, network_sif = []):\n",
    "    \"\"\"\n",
    "    Param:\n",
    "    pa: pypath env, \n",
    "    max_depth: maximum level of reconstruction, \n",
    "    to_be_explore: list of entities, \n",
    "    already_explored=[], \n",
    "    current_depth=0, \n",
    "    network_sif = []\n",
    "    \"\"\"\n",
    "    \n",
    "    # Stopping criteria 1\n",
    "    if current_depth >= max_depth:\n",
    "        print(\"Exploring alted due to maximum depth\")\n",
    "        return network_sif\n",
    "    else:\n",
    "        print('Exploration depth ' + str(current_depth))\n",
    "    # Stopping criteria 2\n",
    "    if len(to_be_explore) == 0:\n",
    "        print(\"Exploring done\")\n",
    "        return(network_sif)\n",
    "    # Start exploring\n",
    "    new_to_be_explored = []\n",
    "    for gene in to_be_explore:\n",
    "        # get entity that get affected by MYC using vertex object (inhibition, stimulation or other)\n",
    "        regulators_list = list(pa.gs_affects(gene))\n",
    "        already_explored.append(gene)\n",
    "        # get direction and sign of interation\n",
    "        for reg in range(len(regulators_list)):\n",
    "            # direction and sign\n",
    "            edge = pa.get_edge(regulators_list[reg][\"name\"], gene)\n",
    "            dirs = edge['dirs']\n",
    "            sign_check = dirs.get_sign(dirs.reverse) # reverse: source ===> target\n",
    "            # A pair of boolean values means if the interaction is stimulation and if it is inhibition, respectively [True, False] \n",
    "            if sign_check[0] == True and sign_check[1] == False:\n",
    "                sign = 'stimulation'\n",
    "            elif sign_check[0] == False and sign_check[1] == True: \n",
    "                sign = 'inhibition'\n",
    "            elif sign_check[0] == True and sign_check[1] == True:\n",
    "                sign = 'stimulation_and_inhibition'\n",
    "            else:\n",
    "                sign = 'unknown'\n",
    "            if regulators_list[reg][\"label\"] not in already_explored:\n",
    "                new_to_be_explored.append(regulators_list[reg][\"label\"])\n",
    "            # ID, name, sign and provenance\n",
    "            network_sif.append({\"source_id\":regulators_list[reg][\"name\"], \"source_name\":regulators_list[reg][\"label\"], \\\n",
    "                \"provenance\":list(regulators_list[reg][\"sources\"]), \"target_name\":gene, \"sign\":sign})\n",
    "    print(\"Depth explored \" + str(current_depth))\n",
    "    current_depth += 1\n",
    "    _upstream_signaling(pa, max_depth, new_to_be_explored, already_explored, current_depth, network_sif)\n",
    "    return network_sif\n",
    "\n",
    "\n",
    "def _print_to_csv(network, output_path):\n",
    "    \"\"\"\n",
    "    Param: network, path of output file\n",
    "    \"\"\"\n",
    "    f = open(output_path + \"-temp\", \"w+\")\n",
    "    # set headers\n",
    "    #f.write(\"source_id,source_name,target_name,sign,provenance\\n\")\n",
    "    for e in network:\n",
    "        f.write(e['source_id'] + \",\")\n",
    "        f.write(e['source_name'] + \",\")\n",
    "        f.write(e['target_name'] + \",\")\n",
    "        f.write(e['sign'] + \",\")\n",
    "        f.write(str(' '.join(e['provenance'])) + \"\\n\")\n",
    "    f.close()\n",
    "    # remove duplicate\n",
    "    os.system(\"sort \" + output_path + \"-temp | uniq -c > \" + output_path )\n",
    "    os.system(\"rm \" + output_path + \"-temp\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DEPTH = 8\n",
    "INPUT_GENES = []\n",
    "inputfile_path = 'input-910.csv'\n",
    "outfile_path = 'md08-pypath_omnipathDB.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(inputfile_path, 'rt') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    for row in spamreader:\n",
    "        INPUT_GENES.append(row[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t=== d i s c l a i m e r ===\n",
      "\n",
      "\tAll data coming with this module\n",
      "\teither as redistributed copy or downloaded using the\n",
      "\tprogrammatic interfaces included in the present module\n",
      "\tare available under public domain, are free to use at\n",
      "\tleast for academic research or education purposes.\n",
      "\tPlease be aware of the licences of all the datasets\n",
      "\tyou use in your analysis, and please give appropriate\n",
      "\tcredits for the original sources when you publish your\n",
      "\tresults. To find out more about data sources please\n",
      "\tlook at `pypath.descriptions` and\n",
      "\t`pypath.data_formats.urls`.\n",
      "\n",
      "\t> New session started,\n",
      "\tsession ID: 'im7ng'\n",
      "\tlogfile: './log/im7ng.log'\n",
      "\tpypath version: 0.7.120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Downloading `` from www.uniprot.org -- 0.00B downloaded: : 1.36Mit [01:03, 56.1kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t:: Ready. Resulted `plain text` of type unicode string.                                                                                              \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/582ab5c0b5fffa42fb3e8d1757901ea1-`.\n",
      " > TRIP\n",
      "\t:: Loading 'uniprot-sec' to 'uniprot-pri' mapping table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Downloading `` from www.uniprot.org -- 0.00B downloaded: : 0.00it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t:: Ready. Resulted `plain text` of type unicode string.                                                                                              \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/15ff42ede8eb6a22b432a886075c2203-`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Downloading `sec_ac.txt` from ftp.uniprot.org -- 31.91MB downloaded: 100%|██████████| 31.9M/31.9M [00:13<00:00, 1.87Mit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t:: Ready. Resulted `plain text` of type file object.                                                                                                 \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/49314fe217bf0f2a5544a2c4314b4adf-sec_ac.txt`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Reading from file -- finished: : 0.00it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t:: Loading 'genesymbol' to 'trembl' mapping table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: 100%|██████████| 370/370 [00:00<00:00, 78.8kit/s]\n",
      "        Processing edges -- finished: 100%|██████████| 370/370 [00:00<00:00, 90.2kit/s]\n",
      "        Processing attributes -- finished: 100%|██████████| 370/370 [00:00<00:00, 6.19kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > SPIKE\n",
      "\t:: Loading data from cache previously downloaded from www.cs.tau.ac.il\n",
      "\t:: Extracting zip data                                                                                                                               \n",
      "\t:: Error in `pypath.dataio.spike_interactions()`. Skipping to next resource.\n",
      "\t:: ('File is not a zip file',)\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/site-packages/pypath/main.py\", line 2284, in read_data_file\n",
      "    infile = inputFunc(**settings.inputArgs)\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/site-packages/pypath/dataio.py\", line 7639, in spike_interactions\n",
      "    url, silent=False, large=True, files_needed=['LatestSpikeDB.xml'])\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/site-packages/pypath/curl.py\", line 770, in __init__\n",
      "    self.process_file()\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/site-packages/pypath/curl.py\", line 1221, in process_file\n",
      "    self.extract_file()\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/site-packages/pypath/curl.py\", line 1243, in extract_file\n",
      "    self.extract()\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/site-packages/pypath/curl.py\", line 564, in extract\n",
      "    getattr(self, 'open_%s' % self.type)()\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/site-packages/pypath/curl.py\", line 604, in open_zip\n",
      "    self.zipfile = zipfile.ZipFile(self.fileobj, 'r')\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/zipfile.py\", line 1131, in __init__\n",
      "    self._RealGetContents()\n",
      "  File \"/home/mlefebvre/anaconda2/envs/pybravo/lib/python3.6/zipfile.py\", line 1198, in _RealGetContents\n",
      "    raise BadZipFile(\"File is not a zip file\")\n",
      "\n",
      "\t### ERROR ###### spike_interactions: No such file or dataio function! :(      \n",
      " > SignaLink3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Reading file -- finished: 100%|██████████| 16.3M/16.3M [00:00<00:00, 21.8Mit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t:: Loading 'genesymbol' to 'swissprot' mapping table\n",
      "\t:: Loading 'genesymbol-syn' to 'swissprot' mapping table\n",
      "\t:: Loading 'genesymbol' to 'uniprot' mapping table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: 100%|██████████| 6.94k/6.94k [00:00<00:00, 355kit/s]\n",
      "        Processing edges -- finished: 100%|██████████| 6.94k/6.94k [00:00<00:00, 150kit/s]\n",
      "        Processing attributes -- finished: 100%|██████████| 6.94k/6.94k [00:01<00:00, 3.77kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Guide2Pharma\n",
      "\t:: Loading data from cache previously downloaded from www.guidetopharmacology.org\n",
      "\t:: Ready. Resulted `plain text` of type file object.                                                                                                 \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/61ddc6eb0ff8ef877c52f5d1a81b9db2-interactions.csv`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: : 0.00it [00:00, ?it/s]\n",
      "        Processing edges -- finished: : 0.00it [00:00, ?it/s]\n",
      "        Processing attributes -- finished: : 0.00it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > CA1\n",
      "\t:: Loading data from cache previously downloaded from science.sciencemag.org\n",
      "\t:: Ready. Resulted `zip extracted data` of type dict of unicode strings.                                                                             \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/a221dcf8846ad398634f9997a1011b9e-Maayan_SOM_External_Files.zip`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: 100%|██████████| 1.48k/1.48k [00:00<00:00, 156kit/s]\n",
      "        Processing edges -- finished: 100%|██████████| 1.48k/1.48k [00:00<00:00, 108kit/s]\n",
      "        Processing attributes -- finished: 100%|██████████| 1.48k/1.48k [00:00<00:00, 4.11kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > ARN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: 100%|██████████| 95.0/95.0 [00:00<00:00, 20.4kit/s]\n",
      "        Processing edges -- finished: 100%|██████████| 95.0/95.0 [00:00<00:00, 16.4kit/s]\n",
      "        Processing attributes -- finished: 100%|██████████| 95.0/95.0 [00:00<00:00, 1.47kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > NRF2ome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: 100%|██████████| 109/109 [00:00<00:00, 32.1kit/s]\n",
      "        Processing edges -- finished: 100%|██████████| 109/109 [00:00<00:00, 25.7kit/s]\n",
      "        Processing attributes -- finished: 100%|██████████| 109/109 [00:00<00:00, 1.63kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Macrophage\n",
      "\t:: Loading data from cache previously downloaded from static-content.springer.com\n",
      "\t:: Ready. Resulted `plain text` of type file object.                                                                                                 \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/e7b73bcce14b977a3e384518d40f3637-12918_2010_452_MOESM2_ESM.XLS`.\n",
      "\t:: Loading 'genesymbol-syn' to 'uniprot' mapping table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: 100%|██████████| 4.86k/4.86k [00:00<00:00, 346kit/s]\n",
      "        Processing edges -- finished: 100%|██████████| 4.86k/4.86k [00:00<00:00, 141kit/s]\n",
      "        Processing attributes -- finished: 100%|██████████| 4.86k/4.86k [00:00<00:00, 7.90kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > DeathDomain\n",
      "\t:: Loading data from cache previously downloaded from www.deathdomain.org\n",
      "\t:: Ready. Resulted `plain text` of type unicode string.                                                                                              \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/13a21b2a1cae61e0b6ee14f0c6230507-show`.\n",
      "\t:: Loading data from cache previously downloaded from www.deathdomain.org\n",
      "\t:: Ready. Resulted `plain text` of type unicode string.                                                                                              \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/a8a54754a427fd1fd6c4a03cdf4f002f-show`.\n",
      "\t:: Loading data from cache previously downloaded from www.deathdomain.org\n",
      "\t:: Ready. Resulted `plain text` of type unicode string.                                                                                              \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/a0fb2adccfb56fea33fc5666e3242485-show`.\n",
      "\t:: Loading data from cache previously downloaded from www.deathdomain.org\n",
      "\t:: Ready. Resulted `plain text` of type unicode string.                                                                                              \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/16a30a05c470466ec3a7a59f7775c757-show`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: 100%|██████████| 236/236 [00:00<00:00, 64.8kit/s]\n",
      "        Processing edges -- finished: 100%|██████████| 236/236 [00:00<00:00, 67.6kit/s]\n",
      "        Processing attributes -- finished: 100%|██████████| 236/236 [00:00<00:00, 4.29kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > PDZBase\n",
      "\t:: Loading data from cache previously downloaded from abc.med.cornell.edu\n",
      "\t:: Ready. Resulted `plain text` of type unicode string.                                                                                              \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/d16213901cd27de19ef825068fd8faa6-allinteractions`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Processing nodes -- finished: 100%|██████████| 125/125 [00:00<00:00, 18.8kit/s]\n",
      "        Processing edges -- finished: 100%|██████████| 125/125 [00:00<00:00, 22.2kit/s]\n",
      "        Processing attributes -- finished: 100%|██████████| 125/125 [00:00<00:00, 1.56kit/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Signor\n",
      "\t:: Loading data from cache previously downloaded from signor.uniroma2.it\n",
      "\t:: Ready. Resulted `plain text` of type file object.                                                                                                 \n",
      "\t:: Local file at `/home/mlefebvre/.pypath/cache/a357fe979f74a823bf4a42150a6dcf33-download_entity.php`.\n"
     ]
    }
   ],
   "source": [
    "# Init pypath\n",
    "pa = pypath.PyPath()\n",
    "\n",
    "# Load databases\n",
    "with curl.cache_off():\n",
    "   pa.load_resources(data_formats.pathway)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploration depth 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        Setting directions -- finished: 100%|██████████| 12.7k/12.7k [00:14<00:00, 861it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth explored0\n",
      "Exploration depth 1\n",
      "Depth explored1\n",
      "Exploration depth 2\n",
      "Depth explored2\n",
      "Exploration depth 3\n",
      "Depth explored3\n",
      "Exploration depth 4\n",
      "Depth explored4\n",
      "Exploration depth 5\n",
      "Depth explored5\n",
      "Exploration depth 6\n",
      "Depth explored6\n",
      "Exploration depth 7\n",
      "Depth explored7\n",
      "Exploring alted due to maximum depth\n",
      "--- Upstream signaling network in 37.33 seconds ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2fc98ce9a349>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Upstream signaling network in %s seconds ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0m_print_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ea367ce44215>\u001b[0m in \u001b[0;36m_print_to_csv\u001b[0;34m(network, output_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# remove duplicate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sort \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-temp | uniq -c > \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rm \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-temp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "network = _upstream_signaling(pa, MAX_DEPTH, INPUT_GENES)\n",
    "elapsed_time = round((time.time() - start_time), 2)\n",
    "print(\"--- Upstream signaling network in %s seconds ---\" % elapsed_time)\n",
    "_print_to_csv(network, outfile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
